# Бизнес-анализ проекта: Обнаружение поддельных отзывов на товары и сервисы

## 1. Бизнес-анализ проекта (Business Understanding)

### Кто участвует в проекте со стороны заказчика? Кто будет основным пользователем?

* Заказчик отсутствует, проект инициирован лично для портфолио или будущего внедрения.
* Основной пользователь — потенциально e-commerce платформа или маркетплейс (например, Ozon, Wildberries, Amazon).

### Собираем контакты, создаем рабочие чаты

* Персональный проект-трекер в Notion для отслеживания прогресса
* GitHub репозиторий для версионирования кода и документации

### Какова бизнес-цель проекта?

**Цель:** Создать работающий MVP системы детекции фейковых отзывов с измеримыми результатами для демонстрации навыков в области NLP и машинного обучения.

**Проверяемый результат:** Уменьшение доли фейковых отзывов среди опубликованных по сравнению с базовой линией (baseline) по ручной оценке 100 случайных отзывов до/после внедрения системы. Достичь F1-score ≥ 0.75 на тестовой выборке


### Существуют ли какие-то уже разработанные решения? Краткий анализ аналогов

| Решение                               | Подход                                                | Ограничения                                                    |
|---------------------------------------|-------------------------------------------------------|----------------------------------------------------------------|
| Amazon Verified Purchase              | Фильтрация по метаданным                              | Проверяет только оплату покупки, не учитывая наполнение отзыва |
| Trustpilot Verified Reviews           | Фильтрация по авторизации/приглашениям                | Не предотвращает платные фальсификации                         |
| Fakespot, ReviewMeta (веб-приложения) | Мультимодальный анализ + эвристики                    | Закрытый исходный код, не всегда точные                        |
| BERT-классификаторы (Kaggle)          | Используют тексты отзывов                             | Не учитывают поведение пользователей                           |
| Мое решение                           | Строит взаимодействия между пользователями и отзывами | Вычислительная нагрузка                                        |

Мое решение ориентировано на мультимодальность: текст + поведенческие признаки.

## 1.1 Текущая ситуация (Assessing current solution)

### Оцениваем, хватает ли ресурсов для проекта

* Технически — да, ресурсы достаточны для прототипа и MVP.
* Для полноценного продакшн-внедрения может потребоваться сервер с GPU или облачные решения.

### Есть ли доступное железо или его необходимо закупать?

* Локальное железо: NVIDIA RTX 3070 (8GB VRAM) для инференса и экспериментов
* Обучение моделей: Google Colab Pro (до 24 часов непрерывной работы)
* GPU — через облачные ресурсы (ограничено по времени).

### Где и как хранятся данные?

* Источники: открытые датасеты (Amazon, Yelp, Trustpilot) с Kaggle и HuggingFace.
* Хранение: локально, Google Drive, GitHub.
* Используется **DVC** для управления версиями данных и экспериментов.

### Сможет ли заказчик выделить экспертов?

* Нет. Работаю одна.
* Валидация осуществляется вручную и через сравнение с результатами аналогов.

### Риски и план их снижения

| Риск                                           | Комментарий                           | План действий                                                       |
|------------------------------------------------| ------------------------------------- |---------------------------------------------------------------------|
| Невозможно уложиться в сроки                   | Работаю одна, возможны откаты         | Вести простой план в Notion, разбить задачи по фазам                |
| Плохое качество или объем данных               | Возможен перекос классов, шум         | Использовать SMOTE, аугментацию, подбор сбалансированных подвыборок |
| Нет закономерностей                            | Модель не находит устойчивые паттерны | Добавлять поведенческие признаки, использовать графы                |
| Нехватка вычислительных ресурсов для обучения  | Ограничения по времени/мощности       | Минимизировать обучение, дистиллировать модели, снижать объемы      |

---

## 1.2 Решаемые задачи с точки зрения аналитики (Data Mining Goals)

### Формулировка задачи

* Задача классификации: определить, является ли отзыв поддельным (fake) или настоящим (genuine).
* Дополнительно:
  * Обнаружение аномалий (unsupervised anomaly detection)
  * Графовая кластеризация (для выявления групп связанных аккаунтов)

### Метрики оценки:

* **Основные:**

  * `F1-score`
    - дает справедливую оценку при несбалансированных данных
    - False Positive (блокировка честного отзыва) = потеря доверия пользователей
    -  False Negative (пропуск фейка) = ущерб репутации платформы
  * `AUC-ROC` — Для оценки способности модели к разделению классов
  * `Precision@K` — Для ранжирования подозрительных отзывов

* **Вспомогательные:**
  * `Explainability` — SHAP, attention, графовая визуализация (например, GNNExplainer)

### Критерий успешности модели

* `F1-score ≥ 0.75` — модель считается успешной.
* `F1-score ≥ 0.65` — приемлемо для MVP.
* Если результат ниже: провести анализ ошибок, попытаться улучшить за счет новых признаков или смены архитектуры.

---

## 1.3 План проекта (Project Plan)

Методология построена на основе стандарта **CRISP-DM** и включает 6 этапов, каждый из которых раскрыт ниже с учётом практических действий по реализации проекта выявления поддельных отзывов.

### 1. Бизнес-анализ (Business Understanding)

* Определение цели и задач проекта, формулировка проверяемых бизнес-гипотез
* Анализ существующих решений и определение конкурентных преимуществ
* Фиксация рисков и организационных ограничений

### 2. Анализ данных (Data Understanding)

* Сбор доступных открытых данных (Amazon, Yelp, Trustpilot)
* Исследование структуры и распределений: типы данных, пропуски, выбросы
* Проверка качества данных: репрезентативность, полнота, аномалии
* Корреляционный и визуальный анализ, профайлинг данных
* Выделение признаков, потенциально важных для модели
* Результат: Отчет по исследованию данных с рекомендациями по предобработке

### 3. Подготовка данных (Data Preparation)

* Очистка данных: удаление/заполнение пропусков, устранение ошибок, энкодинг
* Предобработка текстов: очистка, нормализация, лемматизация
* Feature engineering: длина текста, время, поведенческие характеристики
* Генерация новых данных: агрегаты, TF-IDF, embeddings, oversampling (SMOTE)
* Результат: Подготовленные train/val/test выборки, сохраненные через DVC

### 4. Моделирование (Modeling)

* Построение базовой модели (Logistic Regression, Decision Tree)
* Обучение более сложных моделей: BERT, XGBoost, GCN
* Подбор гиперпараметров, кросс-валидация
* Сравнение моделей по метрикам качества и объяснимости
* Результат: Обученные модели с метриками качества

### 5. Оценка результата (Evaluation)

* Формулировка результатов в бизнес-терминах: насколько решена задача
* Оценка с точки зрения технических и прикладных метрик (F1, AUC, Precision\@k)
* Анализ ошибок модели и причин сбоев, определение направлений улучшения
* Разбор сильных/слабых сторон проекта и этапов, ретроспектива
* Результат: Финальная оценка качества и отчет по результатам

### 6. Внедрение (Deployment)

* Планирование и реализация API или веб-интерфейса (FastAPI + Streamlit)
* Документация всех компонентов (данные, код, модель, метрики)
* Настройка мониторинга качества модели (деградация, переобучение)
* Поддержка, переобучение модели, добавление новых данных

